---
abstract: As machine learning (ML) and artificial intelligence (AI) models continue to revolutionize retail banking, their application in tasks such as predicting customer behaviour, assessing credit risk, and detecting fraudulent activities has become increasingly complex. While these advanced models offer significant predictive power, they often operate as "black boxes," making their decision-making processes opaque and challenging to interpret. This lack of transparency poses critical issues in retail banking, where trust and clarity are paramount. Through a comprehensive review of the literature on machine learning explainability techniques, this work found that traditional scorecards, which rely on straightforward models like logistic regression, have been surpassed by sophisticated AI systems capable of handling high-dimensional, heterogeneous, and temporally interdependent data. However, these systems' complexity undermines stakeholder confidence and understanding. Current explainability approaches, including model-agnostic techniques such as SHAP (SHapley Additive exPlanations) and LIME (Local Interpretable Model-agnostic Explanations), as well as model-specific techniques such as decision trees and Layer-wise Relevance Propagation (LRP), provide valuable insights but fall short in managing the intricate data structures and interactions characteristic of retail banking. These methods are often limited by their computational demands, instability, and difficulty scaling to more complex models. Therefore, to address these gaps, this study recommends and proposes the development of hybrid models that blend interpretable components with complex AI systems, interactive visualization tools that facilitate dynamic exploration and understanding of model predictions, and the application of natural language processing for automated, accessible explanation generation. By enhancing the explainability of AI models, these approaches aim to improve transparency, regulatory compliance, and stakeholder trust in retail banking, thus paving the way for more accountable and understandable AI-driven decision-making processes.
author_notes:
- Equal contribution
- Equal contribution
authors:
- admin
- Eddwin Cheteni
date: "2024-12-01T00:00:00Z"
doi: "0000-0002-8536-3753"
featured: true
image:
  caption: 'Image credit: [**Unsplash**](https://unsplash.com/photos/pLCdAaMFLTE)'
  focal_point: ""
  preview_only: false
projects:
- example
publication: In *Wowchemy Conference*
publication_short: In *IEEE*
publication_types:
- "1"
publishDate: "2024-12-01T00:00:00Z"
slides: example
summary: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus
  ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.
tags: [machine learning, explainability, banking, scorecards]
title: Explainability in Machine Learning & AI Models for Complex Data Structures on Scorecards Development in Retail Banking
url_code: https://github.com/wowchemy/wowchemy-hugo-themes
url_dataset: https://github.com/wowchemy/wowchemy-hugo-themes
url_pdf: ""
url_poster: ""
url_project: ""
url_slides: ""
url_source: https://github.com/wowchemy/wowchemy-hugo-themes
url_video: https://youtube.com
---

{{% callout note %}}
Click the _Cite_ button above to demo the feature to enable visitors to import publication metadata into their reference management software.
{{% /callout %}}

{{% callout note %}}
Create your slides in Markdown - click the _Slides_ button to check out the example.
{{% /callout %}}

Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/).
